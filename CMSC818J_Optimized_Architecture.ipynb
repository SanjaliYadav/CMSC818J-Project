{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7zjMLPgLaOxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e333ed-af89-4544-ed18-83efde751d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from io import StringIO\n",
        "from scipy.io import mmread\n",
        "from scipy.io import mminfo\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "datAddr = \"/content/drive/MyDrive/CMSC818J_Test/\"\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimized Architecture \n",
        " "
      ],
      "metadata": {
        "id": "XquetqYhjW2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assumptions\n",
        "1. Each multiplication and accumulation takes 3 cycles\n",
        "2. Reading the rows from memory takes 2 cycles\n",
        "3. Storing the result of multiplication and accumulation takes 1 cycle. NO merging required since we are implementing inner product. \n",
        "4. PEs write back the output in parallel and can read the input in parallel\n",
        "5. We will sort 8 rows at a time as our assumption is that given our bandwidth, we can read 8 rows at a time"
      ],
      "metadata": {
        "id": "y7bc1CwVDcqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENUMS for PE_stats\n",
        "BUSY_CYCLES = 1 \n",
        "MAX_NUM_NON_ZEROS = 2\n",
        "MIN_NUM_NON_ZEROS = 3\n",
        "IDLE_CYCLES = 4\n",
        "FIFO_BUFFER_LENGTH = 8\n",
        "\n",
        "total_PEs= 2 # number of PEs available. Can change this number as required\n",
        "PE_stats = []\n",
        "for i in range(total_PEs):\n",
        "  PE_stat = dict()\n",
        "  PE_stat[BUSY_CYCLES] = 0 \n",
        "  PE_stat[MAX_NUM_NON_ZEROS] = 0 \n",
        "  PE_stat[MIN_NUM_NON_ZEROS ] = sys.maxsize\n",
        "  PE_stat[IDLE_CYCLES] = 0 \n",
        "  PE_stats.append(PE_stat)\n",
        "PE_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2TYGwp2C_zY",
        "outputId": "fc5a8666-2593-4aa9-8dc8-981d5ab97321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{1: 0, 4: 0, 2: 0, 3: 9223372036854775807},\n",
              " {1: 0, 4: 0, 2: 0, 3: 9223372036854775807}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ENUMS for PE_stats\n",
        "BUSY_CYCLES = 1 \n",
        "MAX_NUM_NON_ZEROS = 2\n",
        "MIN_NUM_NON_ZEROS = 3\n",
        "IDLE_CYCLES = 4\n",
        "FIFO_BUFFER_LENGTH = 16\n",
        "\n",
        "CYCLES_TO_READ = 8\n",
        "CYCLES_TO_MUL = 4 # per element \n",
        "CYCLES_TO_ACCUMULATE = 2 "
      ],
      "metadata": {
        "id": "5it-wVriX3Cr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_idle_cycles (cycles_num):\n",
        "  for i in range(total_PEs):\n",
        "    PE_stats[i][IDLE_CYCLES] += cycles_num "
      ],
      "metadata": {
        "id": "_P-LemEKz6g1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulates PE MAC operations\n",
        "def PE_mult(output_col_num, TOTAL_NUMBER_OF_CYCLES, PE_num):\n",
        "  PE_to_process = PE_lst.pop(0)\n",
        "  row_num = PE_output_index.pop(0) \n",
        "  accumulation = 0\n",
        "  # PE_stats[PE_num][NUMBER_OF_CYCLES] += 4  * len(PE_to_process)\n",
        "  # optimization for inner product: whichever dictionary has smallest non-zeros, we iterate over that. \n",
        "  if len(B_dict) < len(PE_to_process):\n",
        "    for col,data in B_dict.items():\n",
        "      if col in PE_to_process:\n",
        "        # multiply and then accumulate  \n",
        "        accumulation += PE_to_process[col] * data \n",
        "        PE_stats[PE_num][BUSY_CYCLES] += CYCLES_TO_MUL \n",
        "  else:\n",
        "    for col,data in PE_to_process.items():\n",
        "      if col in B_dict:\n",
        "        # multiply and then accumulate  \n",
        "        accumulation += B_dict[col] * data \n",
        "        PE_stats[PE_num][BUSY_CYCLES] += CYCLES_TO_MUL \n",
        "        \n",
        "  output_mat2[row_num][output_col_num] = accumulation\n",
        "  # Update PE stats\n",
        "  PE_stats[PE_num][IDLE_CYCLES] += CYCLES_TO_ACCUMULATE\n",
        "    \n",
        "  if len(PE_to_process) > PE_stats[PE_num][MAX_NUM_NON_ZEROS]: \n",
        "      PE_stats[PE_num][MAX_NUM_NON_ZEROS] = len(PE_to_process)\n",
        "  elif len(PE_to_process) < PE_stats[PE_num][MIN_NUM_NON_ZEROS]: \n",
        "      PE_stats[PE_num][MIN_NUM_NON_ZEROS] = len(PE_to_process)\n",
        "    \n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "id": "2KF7JUygy4YA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_computer_rows(data_index_A, col_index_A, pointer_index_A, output_row_index, TOTAL_NUMBER_OF_CYCLES):\n",
        "  PE_rows_read = dict() \n",
        "  PE_rows_index = dict()\n",
        "  max_nonzero_per_PE = 0\n",
        "  # Because of FIFO buffer length, there are lower number of cycles\n",
        "  for i in range(FIFO_BUFFER_LENGTH):\n",
        "    if pointer_index_A < mat_csrA_len:\n",
        "      numOfElems = (mat_csr.indptr[pointer_index_A + 1] - mat_csr.indptr[pointer_index_A])\n",
        "      data_row_A = mat_csr.data[data_index_A:numOfElems+data_index_A]\n",
        "      row_A = mat_csr.indices[col_index_A:numOfElems+data_index_A]\n",
        "      if numOfElems in PE_rows_read: \n",
        "        PE_rows_read[numOfElems].append(dict(zip(row_A, data_row_A)))\n",
        "        PE_rows_index[numOfElems].append(output_row_index)\n",
        "        data_index_A += numOfElems\n",
        "        col_index_A += numOfElems\n",
        "        pointer_index_A += 1\n",
        "        output_row_index += 1\n",
        "      else:\n",
        "        PE_rows_read[numOfElems] = []\n",
        "        PE_rows_read[numOfElems].append(dict(zip(row_A, data_row_A)))\n",
        "        PE_rows_index[numOfElems] = []\n",
        "        PE_rows_index[numOfElems].append(output_row_index)\n",
        "        data_index_A += numOfElems\n",
        "        col_index_A += numOfElems\n",
        "        pointer_index_A += 1\n",
        "        output_row_index += 1 \n",
        "      if output_row_index % total_PEs != 0 :\n",
        "        max_nonzero_per_PE = max(max_nonzero_per_PE, numOfElems)\n",
        "      else:\n",
        "        TOTAL_NUMBER_OF_CYCLES += max_nonzero_per_PE * CYCLES_TO_MUL\n",
        "        TOTAL_NUMBER_OF_CYCLES += CYCLES_TO_ACCUMULATE # For accumulation \n",
        "        max_nonzero_per_PE = 0 \n",
        "    else:\n",
        "      break # if there are no more rows to be read  \n",
        "  \n",
        "  non_zero_keys = list(PE_rows_read.keys())\n",
        "  non_zero_keys.sort(reverse = True)\n",
        "  \n",
        "  for k in non_zero_keys:\n",
        "    for PE_rows in PE_rows_read[k]:\n",
        "      PE_lst.append(PE_rows)\n",
        "      PE_output_index.append(PE_rows_index[k].pop(0))\n",
        "  \n",
        "  return (data_index_A, col_index_A, pointer_index_A, output_row_index, TOTAL_NUMBER_OF_CYCLES)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2K3KyTO2D4-u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = os.fsencode(datAddr)\n",
        "for pe_num in range(2, 10, 2):\n",
        "  with open('/content/drive/MyDrive/CMSC818J_Data/Optimized_PE' + str(pe_num) + '_16fifo.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)   \n",
        "    for file in os.listdir(directory):\n",
        "      filename = os.fsdecode(file)\n",
        "      print(filename)\n",
        "\n",
        "      ## Read the file \n",
        "      m = mmread(datAddr+filename)\n",
        "      mat_csr = m.tocsr()\n",
        "      mat_csrB = m.tocsc()\n",
        "\n",
        "      total_PEs= pe_num # number of PEs available. Can change this number as required\n",
        "      PE_stats = []\n",
        "\n",
        "      for i in range(total_PEs):\n",
        "        PE_stat = dict()\n",
        "        PE_stat[BUSY_CYCLES] = 0 \n",
        "        PE_stat[MAX_NUM_NON_ZEROS] = 0 \n",
        "        PE_stat[MIN_NUM_NON_ZEROS ] = sys.maxsize\n",
        "        PE_stat[IDLE_CYCLES] = 0 \n",
        "        PE_stats.append(PE_stat)\n",
        "        PE_stats\n",
        "\n",
        "\n",
        "      mat_csrB_len = len(mat_csrB.indptr) - 1\n",
        "      mat_csrA_len = len(mat_csr.indptr) - 1\n",
        "      output_mat_len = len(mat_csrB.indptr) - 1\n",
        "      PE_num = 0\n",
        "      # acts as the buffer that stores rows to be allocated to PEs\n",
        "      PE_lst = []\n",
        "      PE_output_index = []\n",
        "      # matrix to store the file output \n",
        "      output_mat2 = [[0 for _ in range(output_mat_len)] for _ in range(output_mat_len)]\n",
        "      data_index_B = 0 \n",
        "      row_index_B = 0\n",
        "      pointer_index_B = 0 \n",
        "      output_col_index = 0\n",
        "      output_row_index = 0\n",
        "\n",
        "      # Total number of cycles is whichever PE took the longest \n",
        "      TOTAL_NUMBER_OF_CYCLES = 0 \n",
        "\n",
        "      TOTAL_NUMBER_OF_CYCLES += CYCLES_TO_READ # For reading elements, one time cost rest of them are amortized with PE computations\n",
        "      add_idle_cycles(CYCLES_TO_READ)\n",
        "\n",
        "\n",
        "      for j in range(mat_csrB_len): \n",
        "        # Decode col of matrix B from csc format\n",
        "        numOfElems_B = (mat_csrB.indptr[pointer_index_B + 1] - mat_csrB.indptr[pointer_index_B])\n",
        "        data_row_B = mat_csrB.data[data_index_B:numOfElems_B+data_index_B]\n",
        "        col_B = mat_csrB.indices[row_index_B:numOfElems_B+data_index_B]\n",
        "\n",
        "        # The decoded cols and corresponding data values are zipped into a dictionary \n",
        "        # data structure to easily pattern match with rows when computing inner product\n",
        "        B_dict = dict(zip(col_B, data_row_B))\n",
        "        data_index_B += numOfElems_B\n",
        "        row_index_B += numOfElems_B\n",
        "        pointer_index_B += 1\n",
        "        data_index_A = 0 # these values need to updated in if not PE\n",
        "        col_index_A = 0\n",
        "        pointer_index_A = 0\n",
        "        output_row_index = 0\n",
        "        for i in range(mat_csrA_len):\n",
        "          # Decode rows of matrix A from csr format \n",
        "          if not PE_lst:\n",
        "            data_index_A, col_index_A, pointer_index_A, output_row_index, TOTAL_NUMBER_OF_CYCLES = sort_computer_rows(data_index_A, col_index_A, pointer_index_A, output_row_index, TOTAL_NUMBER_OF_CYCLES)\n",
        "            # allocate it to a PE using round-robin strategy \n",
        "          PE_mult(output_col_index, TOTAL_NUMBER_OF_CYCLES, PE_num)\n",
        "          PE_num = (PE_num + 1) % total_PEs \n",
        "        output_col_index += 1 \n",
        "\n",
        "      output_mat2\n",
        "      output_mat2_reshape = np.reshape(output_mat2, (output_mat_len, output_mat_len))\n",
        "      correct_output = np.dot(m.todense(),m.todense())\n",
        "      # Validates if matrix multiplication is done correctly\n",
        "      print(np.allclose(output_mat2_reshape, correct_output))\n",
        "      max_cycles = []\n",
        "      for pe in range(pe_num):\n",
        "        max_cycles.append(PE_stats[pe][BUSY_CYCLES])\n",
        "      max_num = max(max_cycles)\n",
        "\n",
        "      string = [filename, TOTAL_NUMBER_OF_CYCLES]\n",
        "      for pe in range(pe_num):\n",
        "        for stat_num in range(1, 5, 1):\n",
        "          if stat_num == IDLE_CYCLES:\n",
        "            # assumption is that the rest of the PEs will wait for the main PE\n",
        "            idle_cycles_to_add = max_num - PE_stats[pe][BUSY_CYCLES]\n",
        "            string.append(PE_stats[pe][stat_num] + idle_cycles_to_add)\n",
        "          else:\n",
        "            string.append(PE_stats[pe][stat_num])\n",
        "      writer.writerow(string)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6mQTeT1Pf6Qb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}