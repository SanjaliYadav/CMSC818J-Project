{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zjMLPgLaOxa",
        "outputId": "dc90b64a-21e6-4f99-9542-c1ad07d3f7de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from io import StringIO\n",
        "from scipy.io import mmread\n",
        "from scipy.io import mminfo\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "datAddr = \"/content/drive/MyDrive/CMSC818J_Test/\"\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the matrix in mtx format and convert it to csr format \n",
        "m = mmread(datAddr+'spaceShuttleEntry_3.mtx')\n",
        "mat_csr = m.tocsr()\n",
        "mat_csrB = m.tocsc()"
      ],
      "metadata": {
        "id": "tZYE67M_a8_a"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a small example to test on"
      ],
      "metadata": {
        "id": "aDO77Uu1ixfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row_mat = 10\n",
        "cols_mat= 10\n",
        "\n",
        "mat1 = [[0 for _ in range(cols_mat)] for _ in range(row_mat)]\n",
        "\n",
        "mat1[0][0], mat1[0][1], mat1[0][2], mat1[0][3] = 0,0,8,0\n",
        "mat1[1][0], mat1[1][1], mat1[1][2], mat1[1][3] = 7,9,6,0\n",
        "mat1[2][0], mat1[2][1], mat1[2][2], mat1[2][3] = 0,5,0,4\n",
        "mat1[3][0], mat1[3][1], mat1[3][2], mat1[3][3] = 4,0,0,0\n",
        "mat1[4][0], mat1[4][1], mat1[4][2], mat1[4][3] = 7,0,5,0\n",
        "mat1[5][0], mat1[5][1], mat1[5][2], mat1[5][3] = 4,0,0,0\n",
        "mat1[6][0], mat1[6][1], mat1[6][2], mat1[6][3] = 4,0,0,0\n",
        "mat1[7][0], mat1[7][1], mat1[7][2], mat1[7][3] = 4,0,0,0\n",
        "mat1[8][0], mat1[8][1], mat1[8][2], mat1[8][3] = 4,0,0,0\n",
        "mat1[9][0], mat1[9][1], mat1[9][2], mat1[9][3] = 4,0,0,0\n",
        "print(f'Matrix is {mat1}')\n",
        "mat_csr = sparse.csr_matrix(mat1)\n",
        "mat_csrB = sparse.csc_matrix(mat1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2pgE5-igA3C",
        "outputId": "e8e55cba-b8a3-45de-9187-b01c9d987466"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix is [[0, 0, 8, 0, 0, 0, 0, 0, 0, 0], [7, 9, 6, 0, 0, 0, 0, 0, 0, 0], [0, 5, 0, 4, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [7, 0, 5, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimized Architecture \n",
        " "
      ],
      "metadata": {
        "id": "XquetqYhjW2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assumptions\n",
        "1. Each multiplication and accumulation takes 3 cycles\n",
        "2. Reading the rows from memory takes 2 cycles\n",
        "3. Storing the result of multiplication and accumulation takes 1 cycle. NO merging required since we are implementing inner product. \n",
        "4. PEs write back the output in parallel and can read the input in parallel\n",
        "5. We will sort 8 rows at a time as our assumption is that given our bandwidth, we can read 8 rows at a time"
      ],
      "metadata": {
        "id": "y7bc1CwVDcqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ENUMS for PE_stats\n",
        "NUMBER_OF_CYCLES = 1 \n",
        "MAX_NUM_NON_ZEROS = 2\n",
        "MIN_NUM_NON_ZEROS = 3\n",
        "\n",
        "total_PEs= 2 # number of PEs available. Can change this number as required\n",
        "PE_stats = []\n",
        "for i in range(total_PEs):\n",
        "  PE_stat = dict()\n",
        "  PE_stat[NUMBER_OF_CYCLES] = 0 \n",
        "  PE_stat[MAX_NUM_NON_ZEROS] = 0 \n",
        "  PE_stat[MIN_NUM_NON_ZEROS ] = sys.maxsize\n",
        "  PE_stats.append(PE_stat)\n",
        "PE_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2TYGwp2C_zY",
        "outputId": "60ff29bc-09a9-4cd3-962d-478cddd74d69"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{1: 0, 2: 0, 3: 9223372036854775807}, {1: 0, 2: 0, 3: 9223372036854775807}]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulates PE MAC operations\n",
        "def PE_mult(output_col_num):\n",
        "  PE_to_process = PE_lst.pop(0)\n",
        "  row_num = PE_output_index.pop(0) \n",
        "  accumulation = 0\n",
        "  # optimization for inner product: whichever dictionary has smallest non-zeros, we iterate over that. \n",
        "  if len(B_dict) < len(PE_to_process):\n",
        "    for col,data in B_dict.items():\n",
        "      if col in PE_to_process:\n",
        "        # multiply and then accumulate  \n",
        "        accumulation += PE_to_process[col] * data \n",
        "        PE_stats[PE_num][NUMBER_OF_CYCLES] += 3 \n",
        "  else:\n",
        "    for col,data in PE_to_process.items():\n",
        "      if col in B_dict:\n",
        "        # multiply and then accumulate  \n",
        "        accumulation += B_dict[col] * data \n",
        "        PE_stats[PE_num][NUMBER_OF_CYCLES] += 3 \n",
        "        \n",
        "  output_mat2[row_num][output_col_num] = accumulation\n",
        "  # Update PE stats\n",
        "  PE_stats[PE_num][NUMBER_OF_CYCLES] += 1\n",
        "    \n",
        "  if len(PE_to_process) > PE_stats[PE_num][MAX_NUM_NON_ZEROS]: \n",
        "      PE_stats[PE_num][MAX_NUM_NON_ZEROS] = len(PE_to_process)\n",
        "  elif len(PE_to_process) < PE_stats[PE_num][MIN_NUM_NON_ZEROS]: \n",
        "      PE_stats[PE_num][MIN_NUM_NON_ZEROS] = len(PE_to_process)\n",
        "    \n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "id": "2KF7JUygy4YA"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read rows and put them in dict. Then sort them using keys in dict, where the \n",
        "# keys are number of non-zero and values are correponding rws \n",
        "\n",
        "def read_rows(PE_rows_read, PE_rows_index):\n",
        "  for i in range(8):\n",
        "    if pointer_index_A < mat_csrA_len:\n",
        "      print(pointer_index_A)\n",
        "      numOfElems = (mat_csr.indptr[pointer_index_A + 1] - mat_csr.indptr[pointer_index_A])\n",
        "      data_row_A = mat_csr.data[data_index_A:numOfElems+data_index_A]\n",
        "      row_A = mat_csr.indices[col_index_A:numOfElems+data_index_A]\n",
        "      if numOfElems in PE_rows_read: \n",
        "        PE_rows_read[numOfElems].append(dict(zip(row_A, data_row_A)))\n",
        "        PE_rows_index[numOfElems].append(output_row_index)\n",
        "        data_index_A += numOfElems\n",
        "        col_index_A += numOfElems\n",
        "        pointer_index_A += 1\n",
        "        output_row_index += 1\n",
        "      else:\n",
        "        PE_rows_read[numOfElems] = []\n",
        "        PE_rows_read[numOfElems].append(dict(zip(row_A, data_row_A)))\n",
        "        PE_rows_index[numOfElems] = []\n",
        "        PE_rows_index[numOfElems].append(output_row_index)\n",
        "        data_index_A += numOfElems\n",
        "        col_index_A += numOfElems\n",
        "        pointer_index_A += 1\n",
        "        output_row_index += 1\n",
        "\n",
        "    else:\n",
        "      break # if there are no more rows to be read \n",
        "\n",
        "def sort_computer_rows(data_index_A, col_index_A, pointer_index_A, output_row_index):\n",
        "  PE_rows_read = dict() \n",
        "  PE_rows_index = dict()\n",
        "  for i in range(8):\n",
        "    if pointer_index_A < mat_csrA_len:\n",
        "      numOfElems = (mat_csr.indptr[pointer_index_A + 1] - mat_csr.indptr[pointer_index_A])\n",
        "      data_row_A = mat_csr.data[data_index_A:numOfElems+data_index_A]\n",
        "      row_A = mat_csr.indices[col_index_A:numOfElems+data_index_A]\n",
        "      if numOfElems in PE_rows_read: \n",
        "        PE_rows_read[numOfElems].append(dict(zip(row_A, data_row_A)))\n",
        "        PE_rows_index[numOfElems].append(output_row_index)\n",
        "        data_index_A += numOfElems\n",
        "        col_index_A += numOfElems\n",
        "        pointer_index_A += 1\n",
        "        output_row_index += 1\n",
        "      else:\n",
        "        PE_rows_read[numOfElems] = []\n",
        "        PE_rows_read[numOfElems].append(dict(zip(row_A, data_row_A)))\n",
        "        PE_rows_index[numOfElems] = []\n",
        "        PE_rows_index[numOfElems].append(output_row_index)\n",
        "        data_index_A += numOfElems\n",
        "        col_index_A += numOfElems\n",
        "        pointer_index_A += 1\n",
        "        output_row_index += 1\n",
        "\n",
        "    else:\n",
        "      break # if there are no more rows to be read  \n",
        "  \n",
        "  non_zero_keys = list(PE_rows_read.keys())\n",
        "  non_zero_keys.sort(reverse = True)\n",
        "  \n",
        "  for k in non_zero_keys:\n",
        "    for PE_rows in PE_rows_read[k]:\n",
        "      PE_lst.append(PE_rows)\n",
        "      PE_output_index.append(PE_rows_index[k].pop(0))\n",
        "  \n",
        "  return (data_index_A, col_index_A, pointer_index_A, output_row_index)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2K3KyTO2D4-u"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat_csrB_len = len(mat_csrB.indptr) - 1\n",
        "mat_csrA_len = len(mat_csr.indptr) - 1\n",
        "output_mat_len = len(mat_csrB.indptr) - 1\n",
        "PE_num = 0\n",
        "# acts as the buffer that stores rows to be allocated to PEs\n",
        "PE_lst = []\n",
        "PE_output_index = []\n",
        "# matrix to store the file output \n",
        "output_mat2 = [[0 for _ in range(output_mat_len)] for _ in range(output_mat_len)]\n",
        "data_index_B = 0 \n",
        "row_index_B = 0\n",
        "pointer_index_B = 0 \n",
        "output_col_index = 0\n",
        "output_row_index = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for j in range(mat_csrB_len): \n",
        "  # Decode col of matrix B from csc format\n",
        "  numOfElems_B = (mat_csrB.indptr[pointer_index_B + 1] - mat_csrB.indptr[pointer_index_B])\n",
        "  data_row_B = mat_csrB.data[data_index_B:numOfElems_B+data_index_B]\n",
        "  col_B = mat_csrB.indices[row_index_B:numOfElems_B+data_index_B]\n",
        "\n",
        "  # The decoded cols and corresponding data values are zipped into a dictionary \n",
        "  # data structure to easily pattern match with rows when computing inner product\n",
        "  B_dict = dict(zip(col_B, data_row_B))\n",
        "  data_index_B += numOfElems_B\n",
        "  row_index_B += numOfElems_B\n",
        "  pointer_index_B += 1\n",
        "  data_index_A = 0 # these values need to updated in if not PE\n",
        "  col_index_A = 0\n",
        "  pointer_index_A = 0\n",
        "  output_row_index = 0\n",
        "  for i in range(mat_csrA_len):\n",
        "    # Decode rows of matrix A from csr format \n",
        "    if not PE_lst:\n",
        "      data_index_A, col_index_A, pointer_index_A, output_row_index = sort_computer_rows(data_index_A, col_index_A, pointer_index_A, output_row_index)\n",
        "      # allocate it to a PE using round-robin strategy \n",
        "    PE_mult(output_col_index)\n",
        "    PE_num = (PE_num + 1) % total_PEs \n",
        "  output_col_index += 1 \n",
        "\n"
      ],
      "metadata": {
        "id": "8fTnJfD9jdgF"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KOzWG82lPb1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_mat2\n",
        "output_mat2_reshape = np.reshape(output_mat2, (output_mat_len, output_mat_len))\n",
        "correct_output = np.dot(m.todense(),m.todense())\n",
        "# Validates if matrix multiplication is done correctly\n",
        "print(np.allclose(output_mat2_reshape, correct_output))\n",
        "# prints the number of cycles per PE, max and min number of zeros per PE\n",
        "print(PE_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0xKXudcMSK6",
        "outputId": "44729542-af20-42ee-a8f0-f84e244e5f45"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "[{1: 6769529, 2: 1700, 3: 4}, {1: 6626732, 2: 23, 3: 2}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ideas\n",
        "\n",
        "\n",
        "1. Need to read some rows together (8 for now based on our memory bandwidth)\n",
        "2. Each of those rows read together should be inserted in sorted order in the PE_lst. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3ek-6TUGK5ma"
      }
    }
  ]
}