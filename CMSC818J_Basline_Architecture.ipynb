{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Set up for Google Colab "
      ],
      "metadata": {
        "id": "r3IqirNDJ7QA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zjMLPgLaOxa",
        "outputId": "2b3e0375-e118-4319-9b23-05bf3ff8ab4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from io import StringIO\n",
        "from scipy.io import mmread\n",
        "from scipy.io import mminfo\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "datAddr = \"/content/drive/MyDrive/CMSC818J_Test/\"\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy import sparse\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XquetqYhjW2Z"
      },
      "source": [
        "## Baseline Architecture \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7bc1CwVDcqu"
      },
      "source": [
        "### Assumptions\n",
        "\n",
        "1.   Each multiplication and accumulation takes 4 cycles\n",
        "2.   Reading the rows from memory takes 4 cycles\n",
        "3.   Storing the output takes 2 cycle \n",
        "4. PEs can read, compute and write back in parallel\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6_Gve1V4f_Y"
      },
      "outputs": [],
      "source": [
        "# Adds the same number of idle cycles to each of PEs\n",
        "def add_idle_cycles (cycles_num):\n",
        "  for i in range(total_PEs):\n",
        "    PE_stats[i][IDLE_CYCLES] += cycles_num "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMz0TYYq2KFA"
      },
      "outputs": [],
      "source": [
        "# Adds the different number of idle cycles to each of PEs by subtracting the \n",
        "# max_non_per_PE which represents the cycles for the slowest PEs from the busy \n",
        "# cycles of the other PEs once after all the allocations are finished. \n",
        "def add_idle_cycles2(idle_cycle_list, max_nonzero_per_PE, PE_stats):\n",
        "  for i in range(total_PEs):\n",
        "    PE_stats[i][IDLE_CYCLES] += max_nonzero_per_PE - idle_cycle_list[i] \n",
        "  return PE_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KF7JUygy4YA"
      },
      "outputs": [],
      "source": [
        "# Simulates PE MAC operations\n",
        "def PE_mult(output_col_num, PE_num):\n",
        "  total_cycles_spent = 0 \n",
        "  PE_to_process = PE_lst.pop(0)\n",
        "  row_num = PE_output_index.pop(0) \n",
        "  accumulation = 0\n",
        "\n",
        "  # optimization for inner product: whichever dictionary has smallest non-zeros, we iterate over that. \n",
        "  if len(B_dict) < len(PE_to_process):\n",
        "    for col,data in B_dict.items():\n",
        "      if col in PE_to_process:\n",
        "        # multiply and then accumulate  \n",
        "        accumulation += PE_to_process[col] * data \n",
        "        PE_stats[PE_num][BUSY_CYCLES] += CYCLES_TO_MUL_AND_ACCUMULATE\n",
        "        total_cycles_spent += 1 \n",
        "    output_mat2[row_num][output_col_num] = accumulation \n",
        "  else:\n",
        "    for col,data in PE_to_process.items():\n",
        "      if col in B_dict:\n",
        "        # multiply and then accumulate  \n",
        "        accumulation += B_dict[col] * data \n",
        "        PE_stats[PE_num][BUSY_CYCLES] += CYCLES_TO_MUL_AND_ACCUMULATE\n",
        "        total_cycles_spent += 1 \n",
        "    output_mat2[row_num][output_col_num] = accumulation \n",
        "  \n",
        "  # calculate max and min non-zero per PEs \n",
        "  if len(PE_to_process) > PE_stats[PE_num][MAX_NUM_NON_ZEROS]: \n",
        "      PE_stats[PE_num][MAX_NUM_NON_ZEROS] = len(PE_to_process)\n",
        "  elif len(PE_to_process) < PE_stats[PE_num][MIN_NUM_NON_ZEROS]: \n",
        "      PE_stats[PE_num][MIN_NUM_NON_ZEROS] = len(PE_to_process)\n",
        "  return total_cycles_spent\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-RSIaW2d6M1"
      },
      "outputs": [],
      "source": [
        "## ENUMS for PE_stats\n",
        "BUSY_CYCLES = 1\n",
        "MAX_NUM_NON_ZEROS = 2\n",
        "MIN_NUM_NON_ZEROS = 3\n",
        "IDLE_CYCLES = 4\n",
        "CYCLE_TO_READ = 4\n",
        "CYCLES_TO_MUL_AND_ACCUMULATE = 6 # per element multiplication\n",
        "WRITE_BACK_RATE = 1000 # can write 1000 elements at a time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checks whether the busy and idle cycles add up to the total number of \n",
        "# cycles for each of the output files.  \n",
        "def check_cycle_accuracy(filename):\n",
        "  for pe in PE_stats:\n",
        "    if pe[BUSY_CYCLES] + pe[IDLE_CYCLES] != TOTAL_NUMBER_OF_CYCLES:\n",
        "      print(filename + \" Doesn't match up\" + str(total_PEs))\n"
      ],
      "metadata": {
        "id": "rdlr3uNQUiRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZczGl_FLnATs"
      },
      "outputs": [],
      "source": [
        " # Read the rows from matrices and store them to allocate to PEs\n",
        "def sort_computer_rows(data_index_A, col_index_A, pointer_index_A, output_row_index):\n",
        "  PE_rows_read = dict() \n",
        "  PE_rows_index = dict()\n",
        "\n",
        "\n",
        " # read the rows from memory \n",
        "  for i in range(total_PEs):\n",
        "    if pointer_index_A < mat_csrA_len:\n",
        "      numOfElems = (mat_csr.indptr[pointer_index_A + 1] - mat_csr.indptr[pointer_index_A])\n",
        "      data_row_A = mat_csr.data[data_index_A:numOfElems+data_index_A]\n",
        "      row_A = mat_csr.indices[col_index_A:numOfElems+data_index_A]\n",
        "      PE_lst.append(dict(zip(row_A, data_row_A)))\n",
        "      PE_output_index.append(output_row_index)\n",
        "      data_index_A += numOfElems\n",
        "      col_index_A += numOfElems\n",
        "      pointer_index_A += 1\n",
        "      output_row_index += 1\n",
        "    else:\n",
        "      break\n",
        "       \n",
        "  return (data_index_A, col_index_A, pointer_index_A, output_row_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resets the cycle based on \n",
        "def reset_cycle_list(lst):\n",
        "  for i in range(len(lst)):\n",
        "    lst[i] = 0"
      ],
      "metadata": {
        "id": "2x-ahqHkdveP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApFzexdvq800"
      },
      "outputs": [],
      "source": [
        "# Read the matrices and multiply them by each other \n",
        "directory = os.fsencode(datAddr)\n",
        "\n",
        "for pe_num in range(2, 10, 2):\n",
        "  with open('/content/drive/MyDrive/CMSC818J_Data/Baseline_PE' + str(pe_num) + '.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)    \n",
        "    for file in os.listdir(directory):\n",
        "        filename = os.fsdecode(file)\n",
        "        print(filename)\n",
        "\n",
        "        ## Read the file \n",
        "        m = mmread(datAddr+filename)\n",
        "        mat_csr = m.tocsr()\n",
        "        mat_csrB = m.tocsc()\n",
        "\n",
        "        ## Init for PE stats \n",
        "        total_PEs = pe_num # number of PEs available. Can change this number as required\n",
        "        PE_stats = []\n",
        "        for i in range(total_PEs):\n",
        "          PE_stat = dict()\n",
        "          PE_stat[BUSY_CYCLES] = 0  \n",
        "          PE_stat[MAX_NUM_NON_ZEROS] = 0 \n",
        "          PE_stat[MIN_NUM_NON_ZEROS ] = sys.maxsize\n",
        "          PE_stat[IDLE_CYCLES] = 0\n",
        "          PE_stats.append(PE_stat)\n",
        "        PE_stats\n",
        "\n",
        "        max_nonzero_per_PE = 0 # keeps track of max number of nonzero per PE in one allocation cycle\n",
        "        idle_cycle_list = [] # keeps track of idle cycles for each PE per allocation\n",
        "        accum_cycle_list = []\n",
        "\n",
        "        for i in range(total_PEs):\n",
        "          idle_cycle_list.append(0)\n",
        "          accum_cycle_list.append(0)\n",
        "\n",
        "\n",
        "        mat_csrB_len = len(mat_csrB.indptr) - 1\n",
        "        mat_csrA_len = len(mat_csr.indptr) - 1\n",
        "        output_mat_len = len(mat_csrB.indptr) - 1\n",
        "        PE_num = 0\n",
        "        TOTAL_NUMBER_OF_CYCLES = 0\n",
        "\n",
        "        TOTAL_NUMBER_OF_CYCLES += CYCLE_TO_READ # For reading elements, one time cost rest of them are amortized with PE computations\n",
        "        add_idle_cycles(CYCLE_TO_READ)\n",
        "        # acts as the buffer that stores rows to be allocated to PEs\n",
        "        PE_lst = []\n",
        "        PE_output_index = []\n",
        "        # matrix to store the output \n",
        "        output_mat2 = [[0 for _ in range(output_mat_len)] for _ in range(output_mat_len)]\n",
        "        data_index_B = 0 \n",
        "        row_index_B = 0\n",
        "        pointer_index_B = 0 \n",
        "        output_col_index = 0\n",
        "        output_row_index = 0\n",
        "\n",
        "\n",
        "        for j in range(mat_csrB_len): \n",
        "          # Decode col of matrix B from csc format\n",
        "          numOfElems_B = (mat_csrB.indptr[pointer_index_B + 1] - mat_csrB.indptr[pointer_index_B])\n",
        "          data_row_B = mat_csrB.data[data_index_B:numOfElems_B+data_index_B]\n",
        "          col_B = mat_csrB.indices[row_index_B:numOfElems_B+data_index_B]\n",
        "\n",
        "          # The decoded cols and corresponding data values are zipped into a dictionary \n",
        "          # data structure to easily pattern match with rows when computing inner product\n",
        "          B_dict = dict(zip(col_B, data_row_B))\n",
        "          data_index_B += numOfElems_B\n",
        "          row_index_B += numOfElems_B\n",
        "          pointer_index_B += 1\n",
        "          data_index_A = 0\n",
        "          col_index_A = 0\n",
        "          pointer_index_A = 0\n",
        "          output_row_index = 0\n",
        "          for i in range(mat_csrA_len):\n",
        "            # Decode rows of matrix A from csr format \n",
        "            if not PE_lst:\n",
        "              data_index_A, col_index_A, pointer_index_A, output_row_index = \n",
        "              sort_computer_rows(data_index_A, col_index_A, pointer_index_A, output_row_index)\n",
        "            # allocate it to a PE using round-robin strategy \n",
        "            total_computation_cycles = PE_mult(output_col_index, PE_num)\n",
        "\n",
        "            # Calculate the idle cycles after each finishing each allocation \n",
        "            # idle_cycle_list keeps track of number of busy cycles per allocation for \n",
        "            # each PE. At the end, the PE with the max busy cycle is used to calculate \n",
        "            # idle cycles for other PEs. The add_idle_cycles2 computes the number of cycles \n",
        "            # each PE has to wait for the slowest PE to finish computation. \n",
        "            # The accum_cycle_list keeps track of the number of idle cycles for each PE \n",
        "            # while the output is being written back to output buffer. \n",
        "            if PE_num != total_PEs - 1:\n",
        "              max_nonzero_per_PE = max(max_nonzero_per_PE, total_computation_cycles)\n",
        "              idle_cycle_list[PE_num] = total_computation_cycles * CYCLES_TO_MUL_AND_ACCUMULATE\n",
        "              accum_cycle_list[PE_num] = math.ceil(total_computation_cycles/WRITE_BACK_RATE)\n",
        "              PE_stats[PE_num][IDLE_CYCLES] += math.ceil(total_computation_cycles/WRITE_BACK_RATE)\n",
        "              if i == mat_csrA_len - 1:\n",
        "                TOTAL_NUMBER_OF_CYCLES += max_nonzero_per_PE * CYCLES_TO_MUL_AND_ACCUMULATE \n",
        "                TOTAL_NUMBER_OF_CYCLES += math.ceil(max_nonzero_per_PE/WRITE_BACK_RATE)\n",
        "                PE_stats = add_idle_cycles2(idle_cycle_list, max_nonzero_per_PE * CYCLES_TO_MUL_AND_ACCUMULATE, PE_stats)\n",
        "                PE_stats = add_idle_cycles2(accum_cycle_list, math.ceil(max_nonzero_per_PE/WRITE_BACK_RATE), PE_stats)\n",
        "                max_nonzero_per_PE = 0  \n",
        "                reset_cycle_list(accum_cycle_list)\n",
        "                reset_cycle_list(idle_cycle_list)\n",
        "            else:\n",
        "              max_nonzero_per_PE = max(max_nonzero_per_PE, total_computation_cycles)\n",
        "              PE_stats[PE_num][IDLE_CYCLES] += math.ceil(total_computation_cycles/WRITE_BACK_RATE)\n",
        "              accum_cycle_list[PE_num] = math.ceil(total_computation_cycles/WRITE_BACK_RATE)\n",
        "              idle_cycle_list[PE_num] = total_computation_cycles * CYCLES_TO_MUL_AND_ACCUMULATE\n",
        "              TOTAL_NUMBER_OF_CYCLES += max_nonzero_per_PE * CYCLES_TO_MUL_AND_ACCUMULATE \n",
        "              TOTAL_NUMBER_OF_CYCLES += math.ceil(max_nonzero_per_PE/WRITE_BACK_RATE)\n",
        "              PE_stats = add_idle_cycles2(idle_cycle_list, max_nonzero_per_PE * CYCLES_TO_MUL_AND_ACCUMULATE, PE_stats)\n",
        "              PE_stats = add_idle_cycles2(accum_cycle_list, math.ceil(max_nonzero_per_PE/WRITE_BACK_RATE), PE_stats)\n",
        "              max_nonzero_per_PE = 0  \n",
        "              reset_cycle_list(accum_cycle_list)\n",
        "              reset_cycle_list(idle_cycle_list)\n",
        "            PE_num = (PE_num + 1) % total_PEs \n",
        "          output_col_index += 1 \n",
        "\n",
        "        # reshape the output matrix so that it can validated \n",
        "        output_mat2_reshape = np.reshape(output_mat2, (output_mat_len, output_mat_len))\n",
        "        correct_output = np.dot(m.todense(),m.todense())\n",
        "        # Validates if matrix multiplication is done correctly\n",
        "        print(np.allclose(output_mat2_reshape, correct_output))\n",
        "        check_cycle_accuracy(filename)\n",
        "        # prints the number of cycles per PE, max and min number of zeros per PE\n",
        "        string = [filename, TOTAL_NUMBER_OF_CYCLES]\n",
        "        for pe in range(pe_num):\n",
        "          for stat_num in range(1, 5, 1):\n",
        "            string.append(PE_stats[pe][stat_num])\n",
        "        # write back the result to the file \n",
        "        writer.writerow(string)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the matrices and multiply them by a randomly generated matrix\n",
        "directory = os.fsencode(datAddr)\n",
        "for pe_num in range(2, 10, 2):\n",
        "\n",
        "  with open('/content/drive/MyDrive/CMSC818J_Data/BaselineAB_PE' + str(pe_num) + '.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)    \n",
        "    for file in os.listdir(directory):\n",
        "        filename = os.fsdecode(file)\n",
        "        print(filename)\n",
        "\n",
        "        ## Read the file \n",
        "        m = mmread(datAddr+filename)\n",
        "        m2 = mmread(\"/content/drive/MyDrive/psmigr_3.mtx\") # serves as the random matrix \n",
        "        mat_csr = m.tocsr()\n",
        "        mat_csrB = m2.tocsc()\n",
        "        mat_csrB.resize(mat_csr.shape) # reshape so that it can be multiplied to first matrix\n",
        "\n",
        "        ## Init for PE stats \n",
        "        total_PEs = pe_num # number of PEs available. Can change this number as required\n",
        "        PE_stats = [] # keeps track of metrics \n",
        "        for i in range(total_PEs):\n",
        "          PE_stat = dict()\n",
        "          PE_stat[BUSY_CYCLES] = 0  \n",
        "          PE_stat[MAX_NUM_NON_ZEROS] = 0 \n",
        "          PE_stat[MIN_NUM_NON_ZEROS ] = sys.maxsize\n",
        "          PE_stat[IDLE_CYCLES] = 0\n",
        "          PE_stats.append(PE_stat)\n",
        "        PE_stats\n",
        "\n",
        "        max_nonzero_per_PE = 0 # keeps track of max number of nonzero per PE in one allocation cycle\n",
        "        idle_cycle_list = [] # keeps track of idle cycles for each PE per allocation\n",
        "        accum_cycle_list = []\n",
        "\n",
        "        for i in range(total_PEs):\n",
        "          idle_cycle_list.append(0)\n",
        "          accum_cycle_list.append(0)\n",
        "\n",
        "\n",
        "        mat_csrB_len = len(mat_csrB.indptr) - 1\n",
        "        mat_csrA_len = len(mat_csr.indptr) - 1\n",
        "        # output matrix size\n",
        "        output_mat_lenX = len(mat_csr.indptr) - 1\n",
        "        output_mat_lenY = len(mat_csrB.indptr) - 1\n",
        "        PE_num = 0\n",
        "        TOTAL_NUMBER_OF_CYCLES = 0\n",
        "\n",
        "        TOTAL_NUMBER_OF_CYCLES += CYCLE_TO_READ # For reading elements, one time cost rest of them are amortized with PE computations\n",
        "        add_idle_cycles(CYCLE_TO_READ)\n",
        "        # acts as the buffer that stores rows to be allocated to PEs\n",
        "        PE_lst = []\n",
        "        PE_output_index = []\n",
        "        # matrix to store the file output \n",
        "        output_mat2 = np.zeros((output_mat_lenX, output_mat_lenY))\n",
        "        data_index_B = 0 \n",
        "        row_index_B = 0\n",
        "        pointer_index_B = 0 \n",
        "        output_col_index = 0\n",
        "        output_row_index = 0\n",
        "\n",
        "\n",
        "        for j in range(mat_csrB_len): \n",
        "          # Decode col of matrix B from csc format\n",
        "          numOfElems_B = (mat_csrB.indptr[pointer_index_B + 1] - mat_csrB.indptr[pointer_index_B])\n",
        "          data_row_B = mat_csrB.data[data_index_B:numOfElems_B+data_index_B]\n",
        "          col_B = mat_csrB.indices[row_index_B:numOfElems_B+data_index_B]\n",
        "\n",
        "          # The decoded cols and corresponding data values are zipped into a dictionary \n",
        "          # data structure to easily pattern match with rows when computing inner product\n",
        "          B_dict = dict(zip(col_B, data_row_B))\n",
        "          data_index_B += numOfElems_B\n",
        "          row_index_B += numOfElems_B\n",
        "          pointer_index_B += 1\n",
        "          data_index_A = 0\n",
        "          col_index_A = 0\n",
        "          pointer_index_A = 0\n",
        "          output_row_index = 0\n",
        "          for i in range(mat_csrA_len):\n",
        "            # Decode rows of matrix A from csr format \n",
        "            if not PE_lst:\n",
        "              data_index_A, col_index_A, pointer_index_A, output_row_index = sort_computer_rows(data_index_A, col_index_A, pointer_index_A, output_row_index)\n",
        "            # allocate it to a PE using round-robin strategy \n",
        "            total_computation_cycles = PE_mult(output_col_index, PE_num)\n",
        "\n",
        "            # Calculate the idle cycles after each finishing each allocation \n",
        "            # idle_cycle_list keeps track of number of busy cycles per allocation for \n",
        "            # each PE. At the end, the PE with the max busy cycle is used to calculate \n",
        "            # idle cycles for other PEs. The add_idle_cycles2 computes the number of cycles \n",
        "            # each PE has to wait for the slowest PE to finish computation. \n",
        "            # The accum_cycle_list keeps track of the number of idle cycles for each PE \n",
        "            # while the output is being written back to output buffer. \n",
        "            if PE_num != total_PEs - 1:\n",
        "              max_nonzero_per_PE = max(max_nonzero_per_PE, total_computation_cycles)\n",
        "              idle_cycle_list[PE_num] = total_computation_cycles * CYCLES_TO_MUL_AND_ACCUMULATE\n",
        "              accum_cycle_list[PE_num] = math.ceil(total_computation_cycles/WRITE_BACK_RATE)\n",
        "              PE_stats[PE_num][IDLE_CYCLES] += math.ceil(total_computation_cycles/WRITE_BACK_RATE)\n",
        "              if i == mat_csrA_len - 1:\n",
        "                TOTAL_NUMBER_OF_CYCLES += max_nonzero_per_PE * CYCLES_TO_MUL_AND_ACCUMULATE \n",
        "                TOTAL_NUMBER_OF_CYCLES += math.ceil(max_nonzero_per_PE/WRITE_BACK_RATE)\n",
        "                PE_stats = add_idle_cycles2(idle_cycle_list, max_nonzero_per_PE * CYCLES_TO_MUL_AND_ACCUMULATE, PE_stats)\n",
        "                PE_stats = add_idle_cycles2(accum_cycle_list, math.ceil(max_nonzero_per_PE/WRITE_BACK_RATE), PE_stats)\n",
        "                max_nonzero_per_PE = 0  \n",
        "                reset_cycle_list(accum_cycle_list)\n",
        "                reset_cycle_list(idle_cycle_list)\n",
        "            else:\n",
        "              max_nonzero_per_PE = max(max_nonzero_per_PE, total_computation_cycles)\n",
        "              PE_stats[PE_num][IDLE_CYCLES] += math.ceil(total_computation_cycles/WRITE_BACK_RATE)\n",
        "              accum_cycle_list[PE_num] = math.ceil(total_computation_cycles/WRITE_BACK_RATE)\n",
        "              idle_cycle_list[PE_num] = total_computation_cycles * CYCLES_TO_MUL_AND_ACCUMULATE\n",
        "              TOTAL_NUMBER_OF_CYCLES += max_nonzero_per_PE * CYCLES_TO_MUL_AND_ACCUMULATE \n",
        "              TOTAL_NUMBER_OF_CYCLES += math.ceil(max_nonzero_per_PE/WRITE_BACK_RATE)\n",
        "              PE_stats = add_idle_cycles2(idle_cycle_list, max_nonzero_per_PE * CYCLES_TO_MUL_AND_ACCUMULATE, PE_stats)\n",
        "              PE_stats = add_idle_cycles2(accum_cycle_list, math.ceil(max_nonzero_per_PE/WRITE_BACK_RATE), PE_stats)\n",
        "              max_nonzero_per_PE = 0  \n",
        "              reset_cycle_list(accum_cycle_list)\n",
        "              reset_cycle_list(idle_cycle_list)\n",
        "            PE_num = (PE_num + 1) % total_PEs \n",
        "          output_col_index += 1 \n",
        "\n",
        "        # reshape the output matrix so that it can validated \n",
        "        output_mat2_reshape = np.reshape(output_mat2, (output_mat_lenX, output_mat_lenY))\n",
        "        correct_output = (mat_csr * mat_csrB).todense()   \n",
        "        # Validates if matrix multiplication is done correctly\n",
        "        print(np.allclose(output_mat2_reshape, correct_output))\n",
        "        check_cycle_accuracy(filename)\n",
        "        # prints the number of cycles per PE, max and min number of zeros per PE\n",
        "        string = [filename, TOTAL_NUMBER_OF_CYCLES]\n",
        "        for pe in range(pe_num):\n",
        "          for stat_num in range(1, 5, 1):\n",
        "            string.append(PE_stats[pe][stat_num])\n",
        "        # write back the result to the file \n",
        "        writer.writerow(string)"
      ],
      "metadata": {
        "id": "vRrtY-zv6I0K"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}